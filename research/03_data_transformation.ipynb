{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Omar\\\\Desktop\\\\Omar_Files\\\\Python_Analysis\\\\EndToEndMLProjectGenderClassification\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Omar\\\\Desktop\\\\Omar_Files\\\\Python_Analysis\\\\EndToEndMLProjectGenderClassification'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransfornmationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    drop_cols:str\n",
    "    lblenc_cols:str\n",
    "    ordinal_cols:str\n",
    "    trans_cols:str\n",
    "    numerical_cols:str\n",
    "    target_cols:str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EndToEndMLProjectGenderClassification.constants import *\n",
    "from EndToEndMLProjectGenderClassification.utils.common import read_yaml,create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_filepath=CONFIG_FILE_PATH,\n",
    "                 params_filepath=PARAMS_FILE_PATH,\n",
    "                 schema_filepath=SCHEMA_FILE_PATH) -> None:\n",
    "        \n",
    "        self.config=read_yaml(config_filepath)\n",
    "        self.params=read_yaml(params_filepath)\n",
    "        self.schema=read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransfornmationConfig:\n",
    "        config=self.config.data_transformation\n",
    "        schema=self.schema\n",
    "    \n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        data_transformation_config  = DataTransfornmationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            drop_cols=schema.DROP_COLUMNS,\n",
    "            lblenc_cols=schema.LABL_ENCODING,\n",
    "            ordinal_cols=schema.ORDINAL_ENCODING,\n",
    "            trans_cols=schema.TRANSFORM_FEATURES,\n",
    "            numerical_cols=schema.NUMERICAL_FEATURES,\n",
    "            target_cols=schema.TARGET_COLUMN\n",
    "        )\n",
    "\n",
    "        return data_transformation_config \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler,OneHotEncoder,OrdinalEncoder,PowerTransformer\n",
    "from EndToEndMLProjectGenderClassification import logger\n",
    "#from EndToEndMLProjectGenderClassification.utils.common import get_size\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import janitor\n",
    "from imblearn.combine import SMOTETomek,SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransfornmation:\n",
    "    def __init__(self,config:DataTransfornmationConfig):\n",
    "        self.config= config\n",
    "\n",
    "    def data_dropping(self):\n",
    "        df=pd.read_csv(self.config.data_path)\n",
    "        df=df.drop(self.config.drop_cols,axis=1)\n",
    "        df=df.sort_values(by=self.config.ordinal_cols).reset_index().drop(\"index\",axis=1)\n",
    "\n",
    "        for col in df.select_dtypes(include=\"object\"):\n",
    "            df[col]=LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "        logger.info(\"data LabelEncoder Done\")     \n",
    "\n",
    "        col_to_move = \"gender\"\n",
    "        if col_to_move in df.columns:\n",
    "            df = df[[col for col in df.columns if col != col_to_move] + [col_to_move]]\n",
    "\n",
    "        logger.info(\"Moving the Target Feature to be the last column in the data set ==> Done\")      \n",
    "  \n",
    "       \n",
    "        train_set,test_set=train_test_split(df,test_size=0.2,random_state=42)\n",
    "\n",
    "        train_set.to_csv(os.path.join(self.config.root_dir,\"train.csv\"),index=False)\n",
    "        test_set.to_csv(os.path.join(self.config.root_dir,\"test.csv\"),index=False)\n",
    "\n",
    "        logger.info(\"Splitting data into train and test subsets ==> Done\")   \n",
    "\n",
    "        #df=df.clean_names()\n",
    "        return train_set,test_set\n",
    "\n",
    "    def data_encoding(self):\n",
    "\n",
    "        transpower_pipe=Pipeline(steps=[\n",
    "            (\"PowerTransformer\",PowerTransformer(method=\"yeo-johnson\"))\n",
    "        ])    \n",
    "\n",
    "        preprocessor=ColumnTransformer(\n",
    "            [\n",
    "                (\"transformer\",transpower_pipe,self.config.trans_cols),\n",
    "                (\"StandardScaler\",StandardScaler(),self.config.numerical_cols)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        logger.info(\"Created preprocessor object using  ColumnTransformer ==> Done\") \n",
    "\n",
    "        logger.info(\"data_encoding  ==> Done\") \n",
    "\n",
    "        return preprocessor\n",
    "      \n",
    "\n",
    "    def train_test_splitting(self):      \n",
    "        \n",
    "        preprocessor=self.data_encoding()\n",
    "    \n",
    "        logger.info(\"got preprocessor object  ==> Done\")\n",
    "\n",
    "        train_set,test_set=self.data_dropping()\n",
    "\n",
    "        logger.info(\"got train_set,test_set from data_dropping()   ==> Done\")\n",
    "\n",
    "        train_set[self.config.trans_cols]=PowerTransformer(method=\"yeo-johnson\").fit_transform(train_set[self.config.trans_cols])\n",
    "        test_set[self.config.trans_cols]=PowerTransformer(method=\"yeo-johnson\").fit_transform(test_set[self.config.trans_cols])\n",
    "\n",
    "        logger.info(\"Apply PowerTransformer() to non normal data   ==> Done\")\n",
    "   \n",
    "        input_train_set,target_train_set=train_set.drop(self.config.target_cols,axis=1),train_set[self.config.target_cols]\n",
    "        input_test_set,target_test_set=test_set.drop(self.config.target_cols,axis=1),test_set[self.config.target_cols]\n",
    "\n",
    "        logger.info(\"define x,y for train and test subsets  ==> Done\")\n",
    "\n",
    "        input_train_set_arry=input_train_set\n",
    "        input_test_set_arry=input_test_set\n",
    "\n",
    "        input_train_set_arry=input_train_set\n",
    "        input_test_set_arry=input_test_set\n",
    "\n",
    "        logger.info(\"Apply preprocessor.fit_transform on input train and transform on input test ==> Done\")     \n",
    "\n",
    "        smt=SMOTEENN(random_state=42,sampling_strategy=\"minority\")\n",
    "        \n",
    "        input_train_set_final,target_train_set_final=smt.fit_resample(input_train_set_arry,target_train_set)\n",
    "        input_test_set_final,target_test_set_final=smt.fit_resample(input_test_set_arry,target_test_set)\n",
    "\n",
    "        logger.info(\"Apply SMOTEENN resampleing with sampling_strategy : minority  ==> Done\") \n",
    "\n",
    "        train_arr=np.c_[input_train_set_final,np.array(target_train_set_final)]\n",
    "        test_arr=np.c_[input_test_set_final,np.array(target_test_set_final)] \n",
    "\n",
    "        logger.info(\"Apply np.c_ to create train_arr and test_arr  ==> Done\") \n",
    "\n",
    "        with open(f\"{self.config.root_dir}/final_train.npy\", 'wb') as file_obj:\n",
    "           np.save(file_obj, train_arr)\n",
    "\n",
    "        with open(f\"{self.config.root_dir}/final_test.npy\", 'wb') as file_obj:\n",
    "           np.save(file_obj, test_arr) \n",
    "\n",
    "        logger.info(\"saving train_arr and test_arr  ==> Done\")    \n",
    "\n",
    "        logger.info(\"Data Splitting is completed\")   \n",
    "\n",
    "              \n",
    "\n",
    "        print(\"=========================\")\n",
    "\n",
    "        logger.info(input_train_set.shape) \n",
    "        logger.info(target_train_set.shape) \n",
    "        logger.info(input_test_set.shape) \n",
    "        logger.info(target_test_set.shape)\n",
    "\n",
    "        print(\"=========================\")\n",
    "\n",
    "        logger.info(input_train_set_arry.shape) \n",
    "        logger.info(input_test_set_arry.shape) \n",
    "\n",
    "        print(\"=========================\")\n",
    "\n",
    "        logger.info(input_train_set_final.shape) \n",
    "        logger.info(target_train_set_final.shape) \n",
    "        logger.info(input_test_set_final.shape) \n",
    "        logger.info(target_test_set_final.shape)\n",
    "\n",
    "        print(\"=========================\")\n",
    "\n",
    "        logger.info(train_arr.shape) \n",
    "        logger.info(test_arr.shape)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-10 20:54:13,375: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-09-10 20:54:13,378: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-09-10 20:54:13,386: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2024-09-10 20:54:13,387: INFO: common: created directory at: artifacts]\n",
      "[2024-09-10 20:54:13,389: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2024-09-10 20:54:13,591: INFO: 2632541926: data LabelEncoder Done]\n",
      "[2024-09-10 20:54:13,595: INFO: 2632541926: Moving the Target Feature to be the last column in the data set ==> Done]\n",
      "[2024-09-10 20:54:13,830: INFO: 2632541926: Splitting data into train and test subsets ==> Done]\n",
      "[2024-09-10 20:54:13,832: INFO: 2632541926: Created preprocessor object using  ColumnTransformer ==> Done]\n",
      "[2024-09-10 20:54:13,833: INFO: 2632541926: data_encoding  ==> Done]\n",
      "[2024-09-10 20:54:13,834: INFO: 2632541926: Created preprocessor object using  ColumnTransformer ==> Done]\n",
      "[2024-09-10 20:54:13,835: INFO: 2632541926: data_encoding  ==> Done]\n",
      "[2024-09-10 20:54:13,836: INFO: 2632541926: got preprocessor object  ==> Done]\n",
      "[2024-09-10 20:54:13,977: INFO: 2632541926: data LabelEncoder Done]\n",
      "[2024-09-10 20:54:13,980: INFO: 2632541926: Moving the Target Feature to be the last column in the data set ==> Done]\n",
      "[2024-09-10 20:54:14,238: INFO: 2632541926: Splitting data into train and test subsets ==> Done]\n",
      "[2024-09-10 20:54:14,239: INFO: 2632541926: got train_set,test_set from data_dropping()   ==> Done]\n",
      "[2024-09-10 20:54:14,308: INFO: 2632541926: define x,y for train and test subsets  ==> Done]\n",
      "[2024-09-10 20:54:14,309: INFO: 2632541926: Apply preprocessor.fit_transform on input train and transform on input test ==> Done]\n",
      "[2024-09-10 20:54:21,204: INFO: 2632541926: Apply SMOTEENN resampleing with sampling_strategy : minority  ==> Done]\n",
      "[2024-09-10 20:54:21,207: INFO: 2632541926: Apply np.c_ to create train_arr and test_arr  ==> Done]\n",
      "[2024-09-10 20:54:21,212: INFO: 2632541926: saving train_arr and test_arr  ==> Done]\n",
      "[2024-09-10 20:54:21,214: INFO: 2632541926: Data Splitting is completed]\n",
      "=========================\n",
      "[2024-09-10 20:54:21,217: INFO: 2632541926: (54284, 7)]\n",
      "[2024-09-10 20:54:21,219: INFO: 2632541926: (54284, 1)]\n",
      "[2024-09-10 20:54:21,221: INFO: 2632541926: (13572, 7)]\n",
      "[2024-09-10 20:54:21,223: INFO: 2632541926: (13572, 1)]\n",
      "=========================\n",
      "[2024-09-10 20:54:21,226: INFO: 2632541926: (54284, 7)]\n",
      "[2024-09-10 20:54:21,229: INFO: 2632541926: (13572, 7)]\n",
      "=========================\n",
      "[2024-09-10 20:54:21,232: INFO: 2632541926: (16490, 7)]\n",
      "[2024-09-10 20:54:21,234: INFO: 2632541926: (16490, 1)]\n",
      "[2024-09-10 20:54:21,236: INFO: 2632541926: (4026, 7)]\n",
      "[2024-09-10 20:54:21,238: INFO: 2632541926: (4026, 1)]\n",
      "=========================\n",
      "[2024-09-10 20:54:21,242: INFO: 2632541926: (16490, 8)]\n",
      "[2024-09-10 20:54:21,244: INFO: 2632541926: (4026, 8)]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransfornmation(config=data_transformation_config)\n",
    "    data_transformation.data_dropping()\n",
    "    data_transformation.data_encoding()\n",
    "    data_transformation.train_test_splitting()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenderClassificationenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
